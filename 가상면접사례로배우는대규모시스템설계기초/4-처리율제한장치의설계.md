## 처리율 제한 장치(rate limiter)

네트워크 시스템에서 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치.

API 요청횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.

**장점**

- DOS(Denial of Service) 공격에 의한 자원고갈을 방지
    - 예시 ) 구글독스 - 사용자당 분당 300회의 read요청만 허용
- 비용절감
    - 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선순의가 높은 API에 더 많은 자원을 할당할 수 있다.
    - third-party api 사용료 절감
- 서버 과부하 막을 수 있다.
    - 사용자의 잘못된 이용패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치를 활용할 수 있다.

### 단계 설정

### **1. 문제 이해 및 설계 범위 확정**

처리율 제한 장치를 구현하는 여러가지 알고리즘이 있는데 이를 잘 설계하는 과정

- 요규사항
    - 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
    - 낮은 응답시간
    - 적은 메모리 사용
    - 분산형 처리율 제한 - 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야함
    - 예외 처리 : 요청이 제한 되었을때는 그 사실을 사용자에게 분명하게 보여주어야한다.
    - 높은 결함 감내성 : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.


### 2. **개략적 설계안 제시 및 동의 구하기**

- 처리율 제한 장치는 어디에 둘것인가?
    - 클라이언트 : 위변조가 가능해, 처리율 제한을 안정적으로 걸 수 있는 곳이 아님
    - 서버
        - 서버측에 제한 장치 두기
        - 처리율 제한 미들웨어를 통해 api서버로 가는 요청을 통제
    - 고민지점들
        - 프로그래밍 언어, 캐시 서비스 등이 서버측 구현을 지원할 정도로 효율이 높은지
        - 마이크로 서비스에 기반하고 있다면, 사용자 인증이나, IP 허용 목록 관리 등을 처리하기 위해 API 게이트 웨이를 이미 설계에 포함시켰다면, 처리율 제한 기능 또한 게이트웨이에 포함시켜야할 수 있다.
        - 처리율 제한 서비스를 개발할 인력이 부족하다면, 상용 API를 쓰는 것이 바람직하다.
- 처리율 제한 알고리즘

  `토큰 버킷 알고리즘`

    - 사전 설정된 양의 토큰이 주기적으로 채워지고, 꽉찬 버킷에는 토큰이 추가 되지 않는다.
    - 기업들에서 API 요청을 throttle하기 위해 알고리즘을 사용한다.
    - `Parameter` **토큰 버킷 크기**(버킷에 담을 수 있는 토큰의 최대 개수), **토큰 공급률(refill rate)**: 초당 몇 개의 토큰이 버킷에 공급되는가
    - Endpoint마다 별도의 버킷을 둔다.
    - 시스템 처리율을 초당으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 vs ip주소별로 처리율을 제한 적용
    - 장점
        - 구현이 쉽고 메모리 사용 측면에서도 효율적
        - 짧은 시간에 집중되는 트래픽도 처리 가능
    - 단점
        - 알고리즘은 버킷 크기와 토큰 공급률이라는 두개의 인자를 가지고 있는데, 이 값을 적절하게 튜닝하는 것은 까다로움

  `누출 버킷 알고리즘`

    - 요청 처리율이 고정되어있다.
    - 큐로 구현되어있음 (FIFO)
    - `Parameter` **버킷 크기 , 처리율**(지정된 시간당 몇개의 항목을 처리할지)
    - 장점
        - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
        - 고정된 처리율을 갖고 있어, 안정적 출력이 필요한 경우 적합
    - 단점
        - 단시간에 많은 트래픽이 몰리는 경우, 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리하지 못하면 최신 요청들이 버려진다.
        - 두개의 인자를 올바르게 튜닝하기 까다로움

  `고정 윈도 카운터 알고리즘`

    - 장점
        - 메모리 효율이 좋다
        - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다
    - 단점
        - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의처리 한도보다 많은 양의 요청을 처리하게 된다.

  `이동 윈도 로깅 알고리즘`

  타임 스탬프를 추적. 타임스탬프 데이터는 보통 레디스의 정렬집합 같은 캐시에 보관.

  새요청이 오면 만료된 타임스탬프는 제거. 만료된 스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.

  새 요청의 타임스탬프를 로그에 추가하고, 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다.

    - 장점
        - 처리율 메커니즘이 정교하다.
    - 단점
        - 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관됨.

  `이동 윈도 카운터 알고리즘`

  고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘 결합

  현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율

    - 장점
        - 평균처리율에 따라 현재 윈도의 상태를 계산하므로, 짧은 시간에 몰리는 트래픽에도 잘 대응할 수 있음
        - 메모리 효율이 좋다
    - 단점
        - 직전 시간대에 도착한 요청이 균등하게 분포되어있다고 가정한 상태에서 추정치를 계산하기에 다소 느슨함.
- 개략적인 아키텍처

  카운터의 값을 데이터베이스에 보관 X, 보통 Redis와 같은 캐시에 저장한다. (빠르고, 시간 기반 만료 정책 지원)

  처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 검사. → 한도에 도달하지 않았다면 요청은 API서버로 전달.


### 3. **상세설계**

- 처리율 한도 초과 트래픽 처리

  클라이언트는 자기 요청이 처리율 제한에 걸리고 있는지를 어떻게 감지하나? 자기 요청이 처리율 제한에 걸ㄹ리기까지 얼마나 많은 요청을 보낼 수 있는지 어떻게 알 수 있나? → **Response Header**

- 설계 과정
    1. 처리율 제한 규칙은 디스크에 보관. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장
    2. 클라이언트가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어에 도달
    3. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다.
- 생길 수 있는 문제점
    1. 경쟁 조건

       레디스에서 카운터의 값을 읽고, 1만큼 증가시키는데 2대의 서버가 값을 읽었음에도 불구하고 분산서버일 경우 +1만 증가됨

       Lock으로 해결할 수 있지만 시스템의 성능을 상당히 떨어뜨림. 루아스크립트 or 정렬집합이라 불리는 레디스 자료구조를 이용한다.

    2. 동기화 이슈

       클라이언트가 매번 다른 제한장치로 보내게됨.

       → 고정 세션으로, 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 방법도 있지만 규모 확장면에서 유연하지 않은 방법. 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 방법이 있음.

- 성능 최적화
    - 여러 데이터 센터 지원. 에지 서버로 보내 트래픽 분산.
    - 최종 일관성 모델 사용.
- 모니터링
    - 채택된 처리율 제한 알고리즘과 정의된 처리율 제한 알고리즘이 효과적이다.